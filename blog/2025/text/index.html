<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Exploring RAG and its components | Aditya Sharma </title> <meta name="author" content="Aditya Sharma"> <meta name="description" content="intro to RAG technology"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adityash23.github.io/blog/2025/text/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Aditya</span> Sharma </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">courses </a> </li> <li class="nav-item active"> <a class="nav-link" href="/_pages/dropdown/">submenus </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Exploring RAG and its components</h1> <p class="post-meta"> Created on July 07, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ml</a>   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   ·   <a href="/blog/category/academic"> <i class="fa-solid fa-tag fa-sm"></i> academic</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="rag">RAG</h2> <p>As the usage of Large Language Models (LLMs) continues to grow, it becomes increasingly important how we retrieve and generate answers to complex queries. RAG (Retrieval-Augmented Generation) is a technology that combines document retrieval with model generation. It involves getting a user query, finding relevant documents, and using those documents as context to generate a more informed and accurate answer. Let’s explore RAG and its various components today!</p> <h2 id="query-translation--">Query translation -</h2> <h3 id="multi-query">Multi Query</h3> <ul> <li>From a single user input, multiple other similar queries (example - paraphrases) are generated and then all of these queries are used for search in the embedding space.</li> <li>It is particularly useful when the original user query might not be suited for the embedding space and will not find any similar documents at the end, the results from all these queries can be combined to give a single, comprehensive output.</li> </ul> <h3 id="rag-fusion">RAG Fusion</h3> <ul> <li>Same as Multi Query wherein each LLM generated query returns a list of documents as output.</li> <li>A ranking is done on all these documents and then the top X ranked documents are passed in to the LLM along with the original user input to give one final answer.</li> </ul> <h3 id="decomposition">Decomposition</h3> <ul> <li>The user input is broken down into sub-questions that will be solved individually.</li> <li>These are then answered sequentially and the result of past questions is used as context when answering future questions.</li> <li>The answer to the last question is then provided as the final output.</li> <li>An alternate version exists where the past answers are not used in future questions. Instead, all individual question-answer pairs are combined at the end to generate a final output to the original user question.</li> </ul> <h3 id="step-back">Step Back</h3> <ul> <li>Instead of answering the user question directly, a more abstract question is generated first and then its response is used to answer the user’s original question.</li> </ul> <h3 id="hyde">HyDe</h3> <ul> <li>To judge how “<em>close</em>” in meaning is one piece of text to another, Cosine Similarity is often used when both the pieces are represented as vectors in the same embedding space.</li> <li>To find a document containing a “<em>close enough</em>” answer to an input question, these 2 can’t be compared directly since they are 2 different entities (a document vs a question).</li> <li>To solve this, a hypothetical document is generated based on the input query and then this document is used to find the similar documents.</li> <li>From the existing set of actual documents with the expectation that this “<em>similar</em>” document will contain answer to the initial user query.</li> </ul> <h2 id="routing">Routing</h2> <p>Directing the user input to the appropriate data source. There are 2 ways to do so -</p> <h3 id="logical-routing">Logical routing</h3> <ul> <li>Uses a model to choose the data source which matches the domain of the query. <h3 id="semantic-routing--">Semantic routing -</h3> </li> <li>It uses internal, pre-defined prompts that are further used to compute a similarity search with the user input.</li> <li>The prompt with the highest similarity decides how the final answer will be generated (example - by specifying the domain of the query).</li> </ul> <h2 id="query-construction">Query construction</h2> <p>Involves going from unstructured, natural language input to structured query object that is tailored to the details provided about the database. Can be used to generate metadata search queries corresponding to an input text command.</p> <h2 id="indexing">Indexing</h2> <p>It involves generating numerical representation of text documents that can be efficiently searched for relevance to user inputs.</p> <h3 id="multi-representation-indexing">Multi representation Indexing</h3> <ul> <li>Each document in the database is converted into a “<em>summary</em>” that contains the document’s information and is optimized for retrieval. The documents and their summaries are linked.</li> <li>Any input question is now matched with a similar “<em>summary</em>” and the output is the document originally linked with this summary.</li> </ul> <h3 id="raptor-indexing">RAPTOR Indexing</h3> <ul> <li>All documents in the database are clustered together and summarized. This process is repeated until 1 summary remains or it has been repeated X times.</li> <li>The user input is now matched with these high-level summaries and thus allows for a lot more documents to be considered at once while generating an output.</li> <li>It shows improvement over simple document similarity search where only top Y documents can be considered at once.</li> </ul> <h3 id="colbert-indexing">ColBERT Indexing</h3> <ul> <li>So far, all techniques embed a whole document into a single vector which might lead to information loss. Instead, ColBERT breaks a document into tokens which are then embedded in the space.</li> <li>Any input query is also broken into tokens and embedded in the same space.</li> <li>For each query token, its similarity is computed against all document tokens and the one with max similarity is chosen.</li> <li>The <strong>Document Similarity Score</strong> is the sum of the similarities of each query token with its corresponding document token that gives max similarity.</li> </ul> <h2 id="crag--corrective-rag">CRAG : Corrective-RAG</h2> <p>This is one of the strategies of <strong>Active RAG</strong> wherein the user query is used to retrieve documents which are then ranked in terms of relevance to the query.</p> <ul> <li>Any relevant documents are passed as is to the context whereas irrelevant documents lead to a query transformation followed by an external information search for this transformed query (example - a web search).</li> <li>The result of this external search is added to the context along with other documents and now a final output is generated.</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/text/">Sustainable Machine Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/text/">First Post</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Aditya Sharma. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>